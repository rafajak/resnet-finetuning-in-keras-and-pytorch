{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.eager.python import tfe\n",
    "tfe.enable_eager_execution()\n",
    "from tensorflow import keras\n",
    "# from tensorflow import keras.preprocessing.imageImageDataGenerator \n",
    "# import tf.contrib.keras.preprocessing.image.ImageDataGenerator as ImageDataGenerator\n",
    "# # keras.preprocessing.image.ImageDataGenerator\n",
    "# import keras\n",
    "# from keras import layers\n",
    "# from keras.preprocessing import image # keras.preprocessing.image\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications import ResNet50\n",
    "# from keras.applications.resnet50 import preprocess_input\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from keras.models import load_model #  keras.models.load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "from livelossplot import PlotLossesKeras\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "\n",
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir ='/mnt/ml-team/homes/rafal.jakubanis/blogpost2-resnet50/data_small/train'\n",
    "valdir = '/mnt/ml-team/homes/rafal.jakubanis/blogpost2-resnet50/data_small/validation'\n",
    "\n",
    "batch_size = 32 #32\n",
    "img_size = 224\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Keras data generators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: figure out how to add preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "#     preprocessing_function=keras.applications.resnet50.preprocess_input,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "validation_datagen = keras.preprocessing.image.ImageDataGenerator()\n",
    "#     preprocessing_function=keras.applications.resnet50.preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    traindir,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    target_size=(img_size,img_size))\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    valdir,\n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    target_size=(img_size,img_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pre-trained ResNet50\n",
    "\n",
    "Time to load the pre-trained ResNet model. We'll freeze all layers, so there's no backpropagation of gradients through the ResNet50 layers (this saves us A LOT of time and resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.set_learning_phase(0) # see https://github.com/keras-team/keras/issues/9214  and https://github.com/keras-team/keras/pull/9965\n",
    "\n",
    "conv_base = keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet')\n",
    "\n",
    "# freeze layers in resnet50\n",
    "for layer in conv_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack trainable, fully-connected (dense) layers on top of it\n",
    "\n",
    "These are the layers, which will have randomly initiated weights: these are the ones we'll actually train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_base.output\n",
    "keras.backend.set_learning_phase(1)\n",
    "model = keras.layers.GlobalAveragePooling2D()(model)\n",
    "\n",
    "# add fc layers\n",
    "model = keras.layers.Dense(128, activation='relu')(model) \n",
    "predictions = keras.layers.Dense(1, activation='sigmoid')(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conv_base.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(conv_base.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_dir = \"./output\"\n",
    "\n",
    "if not os.path.exists(model_checkpoint_dir):\n",
    "    os.mkdir(model_checkpoint_dir)\n",
    "    print('Created directory: ', model_checkpoint_dir)\n",
    "\n",
    "model_checkpoint_dir = model_checkpoint_dir + \"/best_model.hdf5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras API allows us to easily save the model architecture at the stage it reaches the best validation accuracy (or any metric we want to optimize for). The saving is done through ModelCheckpoint callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save_best = keras.callbacks.ModelCheckpoint(model_checkpoint_dir, monitor='val_acc',\n",
    "verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train the model (A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If eager mode wasn't enabled, we could compile train the model using the standard Keras API, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only TF native optimizers are supported in Eager mode.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-647b808afd15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/ml-team/homes/rafal.jakubanis/envs/python3v/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m     if context.executing_eagerly() and not isinstance(\n\u001b[1;32m    166\u001b[0m         optimizer, (tf_optimizer_module.Optimizer, optimizers.TFOptimizer)):\n\u001b[0;32m--> 167\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Only TF native optimizers are supported in Eager mode.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only TF native optimizers are supported in Eager mode."
     ]
    }
   ],
   "source": [
    "# optimizer = keras.optimizers.RMSprop()\n",
    "\n",
    "# model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since we want to see how eager execution works, we'll do it differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that compiling a tf.keras model while tfe.enable_eager_execution() results in: \n",
    "\"ValueError: Only TF native optimizers are supported in Eager mode.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# history = model.fit_generator(generator=train_generator,\n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=validation_generator, \n",
    "#                     steps_per_epoch = train_generator.n // batch_size,\n",
    "#                     validation_steps = validation_generator.n // batch_size,\n",
    "#                     initial_epoch=0,\n",
    "#                     callbacks=[checkpoint_save_best,])\n",
    "#                     #          plot_losses])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# optimizer = tf.keras.optimizers.RMSprop()\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, inputs, labels):\n",
    "    prediction = model(inputs)\n",
    "    \n",
    "    return tf.losses.sigmoid_cross_entropy(logits=prediction, multi_class_labels=tf.expand_dims(labels, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the loss on a single batch to see if it works so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 0.623\n"
     ]
    }
   ],
   "source": [
    "#test forward prop\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    x, y = iter(train_generator).next()\n",
    "    print(\"Initial loss: {:.3f}\".format(loss(model, x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there's something wrong with the below- it's suspiciously slow, compared to the pure keras version..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(2048, 128) dtype=float32, numpy=\n",
       " array([[-0.01560671,  0.03894274,  0.01391688, ..., -0.00737522,\n",
       "         -0.00492744,  0.0169412 ],\n",
       "        [-0.01842074,  0.05016192,  0.04371505, ...,  0.01060552,\n",
       "         -0.02638582, -0.01518007],\n",
       "        [ 0.03870697, -0.00990153,  0.0372727 , ...,  0.0393369 ,\n",
       "          0.0081052 , -0.03920021],\n",
       "        ...,\n",
       "        [-0.00633602,  0.03693205, -0.04665111, ..., -0.03187395,\n",
       "         -0.05339753, -0.00830605],\n",
       "        [-0.01559854, -0.02060005,  0.01769498, ..., -0.04769189,\n",
       "         -0.01922006,  0.03929759],\n",
       "        [-0.01189886, -0.02948019, -0.00610928, ...,  0.02218145,\n",
       "         -0.04089361,  0.04934127]], dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(128,) dtype=float32, numpy=\n",
       " array([ 0.05357934, -0.01406946, -0.02029084,  0.07233132, -0.0009378 ,\n",
       "        -0.00211341,  0.06436323, -0.00967983,  0.07279093,  0.06702536,\n",
       "        -0.00259931, -0.00514135,  0.00640002, -0.01605608,  0.06778348,\n",
       "         0.00190399,  0.00786732,  0.06749006,  0.06311426,  0.0658293 ,\n",
       "         0.06637158, -0.00689157, -0.02698229,  0.06576717,  0.07108361,\n",
       "         0.06645521,  0.0461434 ,  0.00132354, -0.01450066,  0.06796049,\n",
       "        -0.00757526,  0.00548803, -0.00063162,  0.06097519, -0.00104033,\n",
       "         0.0050359 ,  0.071656  , -0.00869069, -0.00534941,  0.06152587,\n",
       "         0.06563348,  0.06815104, -0.01313871, -0.00533842,  0.00289263,\n",
       "         0.06343422, -0.0037045 ,  0.06299954,  0.00148472, -0.00467794,\n",
       "         0.06551699,  0.05751435, -0.01697699,  0.05515157,  0.06416655,\n",
       "         0.00487017, -0.00377484,  0.06693628, -0.0090519 , -0.00292995,\n",
       "         0.05382333,  0.06294948, -0.01647897, -0.01017111,  0.05895241,\n",
       "         0.06442341,  0.00776366,  0.05702943, -0.00726801, -0.00382279,\n",
       "        -0.01693355,  0.06548741,  0.06344575,  0.05890767,  0.07116111,\n",
       "         0.0674454 ,  0.07042201,  0.06263991,  0.06151832,  0.06643445,\n",
       "         0.06530544,  0.07197233,  0.05300586,  0.06282019,  0.07211841,\n",
       "        -0.01301495, -0.01178568, -0.015377  ,  0.06191093, -0.00439715,\n",
       "         0.06112771,  0.07652714, -0.00344491, -0.00391537,  0.00409441,\n",
       "         0.06999415,  0.06457699,  0.06196156,  0.06535233, -0.01143671,\n",
       "         0.06257298, -0.02292691,  0.06985041, -0.01934349,  0.06410451,\n",
       "         0.05963387,  0.00515157,  0.06405401, -0.00783028,  0.00552734,\n",
       "        -0.01817628,  0.05904689, -0.01014817, -0.0010381 , -0.01098892,\n",
       "         0.06277928,  0.06459513,  0.06088167,  0.05832298, -0.00803828,\n",
       "         0.05646272,  0.05381082,  0.06763825, -0.0118646 , -0.01218813,\n",
       "         0.06640276, -0.00918508,  0.06850857], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(128, 1) dtype=float32, numpy=\n",
       " array([[-0.20412363],\n",
       "        [ 0.17088957],\n",
       "        [ 0.20451856],\n",
       "        [-0.144818  ],\n",
       "        [ 0.0783295 ],\n",
       "        [ 0.14638743],\n",
       "        [-0.27537858],\n",
       "        [ 0.1127254 ],\n",
       "        [-0.1278029 ],\n",
       "        [-0.20857644],\n",
       "        [ 0.12779115],\n",
       "        [ 0.2114276 ],\n",
       "        [ 0.03461522],\n",
       "        [ 0.03781331],\n",
       "        [-0.16522042],\n",
       "        [ 0.11111666],\n",
       "        [ 0.07017955],\n",
       "        [-0.13610765],\n",
       "        [-0.12428681],\n",
       "        [-0.20357947],\n",
       "        [-0.11027137],\n",
       "        [ 0.05208208],\n",
       "        [ 0.18445805],\n",
       "        [-0.22641239],\n",
       "        [-0.26703382],\n",
       "        [-0.16673905],\n",
       "        [-0.10067006],\n",
       "        [ 0.18946452],\n",
       "        [ 0.20966975],\n",
       "        [-0.16588202],\n",
       "        [ 0.06794909],\n",
       "        [ 0.16492788],\n",
       "        [ 0.08186755],\n",
       "        [-0.05660297],\n",
       "        [ 0.19884096],\n",
       "        [ 0.17258324],\n",
       "        [-0.24413091],\n",
       "        [ 0.16779833],\n",
       "        [ 0.0548227 ],\n",
       "        [-0.05652053],\n",
       "        [-0.07696874],\n",
       "        [-0.24928775],\n",
       "        [ 0.01472803],\n",
       "        [ 0.1404393 ],\n",
       "        [ 0.20100103],\n",
       "        [-0.25240606],\n",
       "        [ 0.18529373],\n",
       "        [-0.16280891],\n",
       "        [ 0.20714362],\n",
       "        [ 0.1545622 ],\n",
       "        [-0.06925458],\n",
       "        [-0.16280077],\n",
       "        [ 0.10399716],\n",
       "        [-0.05529753],\n",
       "        [-0.24716043],\n",
       "        [ 0.24907045],\n",
       "        [ 0.18644075],\n",
       "        [-0.11920852],\n",
       "        [ 0.10411063],\n",
       "        [ 0.06861258],\n",
       "        [-0.04847734],\n",
       "        [-0.07845727],\n",
       "        [ 0.1720522 ],\n",
       "        [ 0.18108161],\n",
       "        [-0.10770288],\n",
       "        [-0.24374777],\n",
       "        [ 0.09190212],\n",
       "        [-0.0543742 ],\n",
       "        [ 0.09301028],\n",
       "        [ 0.22543135],\n",
       "        [ 0.194707  ],\n",
       "        [-0.19436157],\n",
       "        [-0.0681589 ],\n",
       "        [-0.08568063],\n",
       "        [-0.10790769],\n",
       "        [-0.05561995],\n",
       "        [-0.27012238],\n",
       "        [-0.1459891 ],\n",
       "        [-0.0387953 ],\n",
       "        [-0.10526694],\n",
       "        [-0.05563498],\n",
       "        [-0.12122277],\n",
       "        [-0.0495505 ],\n",
       "        [-0.24135341],\n",
       "        [-0.15843473],\n",
       "        [ 0.05764936],\n",
       "        [ 0.2126043 ],\n",
       "        [ 0.13134812],\n",
       "        [-0.093219  ],\n",
       "        [ 0.22749688],\n",
       "        [-0.1474237 ],\n",
       "        [-0.13390486],\n",
       "        [ 0.07574613],\n",
       "        [ 0.18469541],\n",
       "        [ 0.1633019 ],\n",
       "        [-0.2613011 ],\n",
       "        [-0.05856316],\n",
       "        [-0.06384114],\n",
       "        [-0.20501618],\n",
       "        [ 0.2102302 ],\n",
       "        [-0.06144613],\n",
       "        [-0.00065917],\n",
       "        [-0.22394866],\n",
       "        [ 0.10865743],\n",
       "        [-0.05020488],\n",
       "        [-0.12308831],\n",
       "        [ 0.15538444],\n",
       "        [-0.04526511],\n",
       "        [ 0.06288818],\n",
       "        [ 0.14532691],\n",
       "        [ 0.21608455],\n",
       "        [-0.1578137 ],\n",
       "        [ 0.11171078],\n",
       "        [ 0.03298819],\n",
       "        [ 0.17540707],\n",
       "        [-0.22524644],\n",
       "        [-0.14629889],\n",
       "        [-0.14349556],\n",
       "        [-0.18420231],\n",
       "        [ 0.01184271],\n",
       "        [-0.02937901],\n",
       "        [-0.0709782 ],\n",
       "        [-0.11801077],\n",
       "        [ 0.16891071],\n",
       "        [ 0.08421037],\n",
       "        [-0.20184436],\n",
       "        [ 0.07049683],\n",
       "        [-0.08559055]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(1,) dtype=float32, numpy=array([-0.06155153], dtype=float32)>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 0000: 0.625\n",
      "Loss at step 0001: 0.624\n",
      "Loss at step 0002: 0.624\n",
      "Loss at step 0003: 0.624\n",
      "Loss at step 0004: 0.623\n",
      "Loss at step 0005: 0.623\n",
      "Loss at step 0006: 0.622\n",
      "Loss at step 0007: 0.623\n",
      "Loss at step 0008: 0.623\n",
      "Loss at step 0009: 0.622\n",
      "Loss at step 0010: 0.622\n",
      "Loss at step 0011: 0.622\n",
      "Loss at step 0012: 0.622\n",
      "Loss at step 0013: 0.623\n",
      "Loss at step 0014: 0.622\n",
      "Loss at step 0015: 0.621\n",
      "Loss at step 0016: 0.621\n",
      "Loss at step 0017: 0.621\n",
      "Loss at step 0018: 0.621\n",
      "Loss at step 0019: 0.621\n",
      "Loss at step 0020: 0.621\n",
      "Loss at step 0021: 0.620\n",
      "Loss at step 0022: 0.620\n",
      "Loss at step 0023: 0.619\n",
      "Loss at step 0024: 0.619\n",
      "Loss at step 0025: 0.619\n",
      "Loss at step 0026: 0.619\n",
      "Loss at step 0027: 0.619\n",
      "Loss at step 0028: 0.618\n",
      "Loss at step 0029: 0.618\n",
      "Loss at step 0030: 0.619\n",
      "Loss at step 0031: 0.619\n",
      "Loss at step 0032: 0.617\n",
      "Loss at step 0033: 0.613\n",
      "Loss at step 0034: 0.614\n",
      "Loss at step 0035: 0.604\n",
      "Loss at step 0036: 0.606\n",
      "Loss at step 0037: 0.589\n",
      "Loss at step 0038: 0.603\n",
      "Loss at step 0039: 0.606\n",
      "Loss at step 0040: 0.607\n",
      "Loss at step 0041: 0.607\n",
      "Loss at step 0042: 0.606\n",
      "Loss at step 0043: 0.606\n",
      "Loss at step 0044: 0.606\n",
      "Loss at step 0045: 0.606\n",
      "Loss at step 0046: 0.611\n",
      "Loss at step 0047: 0.608\n",
      "Loss at step 0048: 0.608\n",
      "Loss at step 0049: 0.608\n",
      "Loss at step 0050: 0.610\n",
      "Loss at step 0051: 0.617\n",
      "Loss at step 0052: 0.618\n",
      "Loss at step 0053: 0.616\n",
      "Loss at step 0054: 0.618\n",
      "Loss at step 0055: 0.618\n",
      "Loss at step 0056: 0.618\n",
      "Loss at step 0057: 0.618\n",
      "Loss at step 0058: 0.617\n",
      "Loss at step 0059: 0.617\n",
      "Loss at step 0060: 0.615\n",
      "Loss at step 0061: 0.615\n",
      "Loss at step 0062: 0.629\n",
      "Loss at step 0063: 0.628\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-9cbe016edb7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# for epoch in range(epochs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml-team/homes/rafal.jakubanis/envs/python3v/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml-team/homes/rafal.jakubanis/envs/python3v/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1398\u001b[0m     \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1400\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/ml-team/homes/rafal.jakubanis/envs/python3v/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m   1360\u001b[0m           interpolation=self.interpolation)\n\u001b[1;32m   1361\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m       \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml-team/homes/rafal.jakubanis/envs/python3v/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mrandom_transform\u001b[0;34m(self, x, seed)\u001b[0m\n\u001b[1;32m    792\u001b[0m           \u001b[0mimg_channel_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m           \u001b[0mfill_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m           cval=self.cval)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_shift_range\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml-team/homes/rafal.jakubanis/envs/python3v/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(x, transform_matrix, channel_axis, fill_mode, cval)\u001b[0m\n\u001b[1;32m    295\u001b[0m           \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m           cval=cval) for x_channel in x\n\u001b[0m\u001b[1;32m    298\u001b[0m   ]\n\u001b[1;32m    299\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml-team/homes/rafal.jakubanis/envs/python3v/lib/python3.5/site-packages/tensorflow/python/keras/_impl/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    295\u001b[0m           \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m           \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m           cval=cval) for x_channel in x\n\u001b[0m\u001b[1;32m    298\u001b[0m   ]\n\u001b[1;32m    299\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ml-team/homes/rafal.jakubanis/envs/python3v/lib/python3.5/site-packages/scipy/ndimage/interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0;32m--> 458\u001b[0;31m                                       output, order, mode, cval, None, None)\n\u001b[0m\u001b[1;32m    459\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "\n",
    "    # for epoch in range(epochs):\n",
    "    for (batch, (inputs, labels)) in enumerate(train_generator):\n",
    "\n",
    "        grads = grad(model, inputs, labels)\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, model.variables), #changingto model.trainable_variables doesn't improve speed\n",
    "                                    global_step=tf.train.get_or_create_global_step())\n",
    "#         if batch % 200 == 0:\n",
    "#         print(\"Loss at step {:04d}: {:.3f}\".format(batch, loss(model, x, y)))\n",
    "        print(\"Loss at step {:04d}: {:.3f}\".format(batch, loss(model, x, y)))\n",
    "        \n",
    "print(\"Final loss: {:.3f}\".format(loss(model, x, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best model and evaluate it on a sample image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(model_checkpoint_dir, compile=False) #compile causes issues if not turned off - we are not training the model so we don't need to compile the model #the workaround to this user warning error might be to set all weights to not-trainable explicitly (in a loop) https://stackoverflow.com/questions/49195189/error-loading-the-saved-optimizer-keras-python-raspberry\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = \"/mnt/ml-team/homes/rafal.jakubanis/blogpost2-resnet50/data_small/test/cats/cat.1505.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(test_cat, target_size=(img_size, img_size))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "preds = loaded_model.predict(x)\n",
    "preds\n",
    "# pred_class = loaded_model.predict_classes(x)\n",
    "# pred_class = loaded_model.probas_to_classes(x)\n",
    "\n",
    "if preds[0][0] < 0.5:\n",
    "    print(\"IT'S A CAT! ({:.2})\".format(preds[0][0]))\n",
    "else:\n",
    "    print(\"IT'S A DOG! ({:.2})\".format(preds[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.resize((128,128))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
